---
title: Contentlayer, MDX and the vercel edge function size limit
summary: The 1mb size limit of vercel edge functions is quickly reached with Contentlayer and MDX
date: 2022-11-24
image: https://images.unsplash.com/photo-1647666561879-b0a970912037
---

I've recently tried to implement [social media cards with @vercel/og](/posts/2022-11-26-social-media-cards).
The implementation uses an [edge function](https://vercel.com/docs/concepts/functions/edge-functions)
and during development everything went well, until I deployed it to Vercel.
On Vercel the build ended with the following error:

<Notification type="error">
  <strong>Error:</strong> Provided Edge Function is too large
</Notification>

Too large?
I've used only the `@vercel/og` and the `contentlayer/generated` package.
And how large is actually too large?
A quick look at the [vercel documentation](https://vercel.com/docs/concepts/functions/edge-functions#limitations) revealed:

> The maximum size for an Edge Function is 1 MB, including all the code that is bundled in the function.

`1mb` is not very much, but it should be enough for the two imports.

## Analysis

So I installed [@next/bundle-analyzer](https://www.npmjs.com/package/@next/bundle-analyzer) to analyze the generated bundle and
found out what breaks the limit.

<CH.Code>

```bash pnpm
pnpm add -D @next/bundle-analyzer
```

```bash yarn
yarn add -D @next/bundle-analyzer
```

```bash npm
npm install -D @next/bundle-analyzer
```

</CH.Code>

After installing the analyzer we can configure it in the next config:

```js next.config.mjs focus=1,16:20
import NextBundleAnalyzer from "@next/bundle-analyzer";
import { withContentlayer } from "next-contentlayer";

/** @type {import('next').NextConfig} */
const nextConfig = {
  webpack: (config) => {
    // suppress warnings of webpack
    // https://github.com/contentlayerdev/contentlayer/issues/313
    config.infrastructureLogging = {
      level: "error",
    };
    return config;
  },
};

const withBundleAnalyzer = NextBundleAnalyzer({
  enabled: process.env.ANALYZE === "true",
});

export default withContentlayer(withBundleAnalyzer(nextConfig));
```

If we start our build with the environment variable `ANALYZE=true`, the output of the bundle analyzer will be opened in a browser window.
I was pretty much surprised, because the analyzer showed me that the module `contentlayer/generated` is `960k` in size!
After a quick look at the generated file at `.contentlayer/generated/Post/_index.json`,
it became clear that the body of the post needed all the memory.
Especially the code blocks with [Code Hike](https://codehike.org/) need a lot of memory.

## Solutions

Now that we know what caused the problem, we need a solution.

### Load posts dynamically

My first idea was to use `fetch` instead of `import` to get the posts:

```tsx pages/api/og/posts/[slug].tsx
import { type Post } from "contentlayer/generated";

// res.json() results in a parse error,
// res.text() does also not work.
// So we use res.blob() / text() and JSON.parse().
const allPosts = fetch(new URL(`../../../../.contentlayer/generated/Post/_index.json`, import.meta.url))
  .then((res) => res.blob())
  .then((blob) => blob.text())
  .then((text) => JSON.parse(text) as Post[]);
```

As the comments show, there were a few stumbling blocks, but on the whole the implementation was straightforward.
So I deployed my results to Vercel, but unfortunately it showed the same error:

<Notification type="error">
  <strong>Error:</strong> Provided Edge Function is too large
</Notification>

This is strange, because our bundle should be much smaller now.
So I' installed the [vercel cli](https://www.npmjs.com/package/vercel) to see the generated deployment locally.

<CH.Code>

```bash pnpm
pnpm add --global vercel
```

```bash yarn
yarn global add vercel
```

```bash npm
npm install -g vercel
```

</CH.Code>

After the installation we can generate the deployment bundle by calling `vercel build`.
The generated output shows that the bundle size is now `390K`,
but there is a `assets` directory which contains the `_index.json` of contentlayer.

<FileTree
  nodes={[
    {
      type: "directory",
      name: ".vercel/output/functions/api/og/posts/[slug].func/",
      children: [
        {
          type: "directory",
          name: "assets",
          children: [{ type: "file", name: "_index.df90b64bb8d3d072.json", size: 985334 }],
        },
        {
          type: "file",
          name: "index.js",
          size: 399590,
        },
        {
          type: "file",
          name: "index.js.map",
          size: 564330,
        },
      ],
    },
  ]}
/>

It looks like the `assets` directory is also counted and that still exceeds the limit.
So we need an other solution.

### Parameters as part of the url

My second thought was to add the required parameters for the edge function to the url.
So we have a url like the following:

```text
/api/og/posts?summary=Next%20app%20directory%20and%20100%25%20height&description=...
```

The maximum url length is `14KiB` which should be enough for our requirements.
But with such a url it is easy to manipulate the parameters and
to generate a social media card with our layout but with different content.
To avoid such a manipulation we have to sign or encrypt the parameters.
There is an example on Vercel for [encrypting parameters](https://vercel.com/docs/concepts/functions/edge-functions/og-image-examples#encrypting-parameters).
This should work, but it is quite an effort and the urls are still looking awful.
Can we do better?

### Generate json without body

A third idea came to my mind.
We can generate a json, which contains all fields of the posts, but without the body.

```js scripts/posts-withoutbody.mjs
import { allPosts } from "../.contentlayer/generated/index.mjs";
import { mkdir, writeFile } from "fs/promises";

const createJson = () => {
  return allPosts.map((post) => {
    const { body, ...content } = post;
    return content;
  });
};

(async () => {
  console.log(`create posts json without body for ${allPosts.length} paths`);
  const json = createJson();
  await mkdir("./.scripts/Post", {
    recursive: true,
  });
  await writeFile("./.scripts/Post/withoutbody.json", JSON.stringify(json, null, 2), {
    encoding: "utf-8",
  });
})();
```

The script above loads the posts from the contentlayer directory,
removes the body and writes the new file to `./.scripts/Post/withoutbody.json`.
The newly generated file is only `3.9K` large.

Now we have to integrate the script into the build process of our project.

```json package.json focus=3
"scripts": {
  "dev": "next dev",
  "build": "contentlayer build && node scripts/posts-withoutbody.mjs && next build",
  "start": "next start",
  "lint": "next lint"
}
```

First we need to call the contentlayer build,
so that we are able to import it in our script afterwards.
Then we can run our script and finally we can run the next build.

After that build integration we can import the generated json:

```tsx pages/api/og/[slug].tsx
import allPosts from ".scripts/Post/withoutbody.json";
```

To ensure that we are not accidentally adding the generated file to our repository,
we need to add the `.scripts` directory to `.gitignore`.

```text focus=3
/node_modules
.contentlayer
.scripts
```

Now with this solution established, the build also succeeds at Vercel.

<Notification type="success">
  <pre>Build Completed in /vercel/output [44s]
  Deployed outputs in 8s
  Build completed. Populating build cache...
  Uploading build cache [84.14 MB]...
  Build cache uploaded: 1.756s
  Done with "."</pre>
</Notification>

But this solution is only a workaround and there should be a better way backed in contentlayer itself.
For this reason I also opened a ticket [contentlayerdev/contentlayer#339](https://github.com/contentlayerdev/contentlayer/issues/339).
